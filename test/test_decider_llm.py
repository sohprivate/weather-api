import sys
import os
from dotenv import load_dotenv

# LangChainãªã©ã®ãƒ‘ã‚¹ã‚’èªè­˜ã•ã›ã‚‹
sys.path.append(os.path.abspath("."))

from tools.decider_llm import decide_by_llm

load_dotenv()  # .env ã‹ã‚‰ APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿

sample_input = [
    {
        "source": "OpenWeatherMap",
        "max_temp": 12.5,
        "min_temp": 7.2,
        "pop": 70,
        "description": "æ™´ã‚Œæ™‚ã€…æ›‡ã‚Šã§ã™ã€‚å¤œã«é›¨ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    },
    {
        "source": "WeatherAPI",
        "max_temp": 13.1,
        "min_temp": 8.0,
        "pop": 65,
        "description": "åˆå‰ä¸­ã¯æ™´ã‚Œã€åˆå¾Œã¯æ›‡ã‚Šã®ã¡ä¸€æ™‚é›¨ã¨ãªã‚‹ã§ã—ã‚‡ã†ã€‚"
    },
    {
        "source": "Tsukumijima",
        "max_temp": 10.0,
        "min_temp": 6.0,
        "pop": 80,
        "description": "ä¸€æ—¥ã‚’é€šã—ã¦æ›‡ã‚Šã€å¤•æ–¹ã‹ã‚‰å¼±ã„é›¨ã€‚"
    },
    {
        "source": "JMA",
        "max_temp": None,
        "min_temp": None,
        "pop": None,
        "description": "é«˜æ°—åœ§ã«è¦†ã‚ã‚Œã€æ¦‚ã­æ™´ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚"
    }
]

if __name__ == "__main__":
    print("ğŸ§ª Running LLM-based Decider Test...\n")

    result = decide_by_llm(sample_input)
    print("âœ… LLM Decision Result:")
    print(result)
